= Cluster Nodes =

== Defining a Cluster Node ==

Each node in the cluster will have an entry in the nodes section
containing its UUID, uname, and type.

.Example Corosync cluster node entry
======
[source,XML]
<node id="101" uname="pcmk-1"/>
======

In normal circumstances, the admin should let the cluster populate
this information automatically from the communications and membership
data.

[[s-node-name]]
== Where Pacemaker Gets the Node Name ==

Traditionally, Pacemaker required nodes to be referred to by the value
returned by `uname -n`.  This can be problematic for services that
require the `uname -n` to be a specific value (e.g. for a licence
file).

This requirement has been relaxed for clusters using Corosync 2.0 or later.
The name Pacemaker uses is:

. The value stored in +corosync.conf+ under *ring0_addr* in the *nodelist*, if it does not contain an IP address; otherwise
. The value stored in +corosync.conf+ under *name* in the *nodelist*; otherwise
. The value of `uname -n`

Pacemaker provides the `crm_node -n` command which displays the name
used by a running cluster.

If a Corosync *nodelist* is used, `crm_node --name-for-id` pass:[<replaceable>number</replaceable>] is also
available to display the name used by the node with the corosync
*nodeid* of pass:[<replaceable>number</replaceable>], for example: `crm_node --name-for-id 2`.

[[s-node-attributes]]
== Node Attributes ==

indexterm:[Node,attribute]
'Node attributes' are a special type of option (name-value pair) that
applies to a node object.

Beyond the basic definition of a node, the administrator can
describe the node's attributes, such as how much RAM, disk, what OS or
kernel version it has, perhaps even its physical location.  This
information can then be used by the cluster when deciding where to
place resources.  For more information on the use of node attributes,
see <<ch-rules>>.

Node attributes can be specified ahead of time or populated later,
when the cluster is running, using `crm_attribute`.

Below is what the node's definition would look like if the admin ran the command:
      
.Result of using crm_attribute to specify which kernel pcmk-1 is running
======
-------
# crm_attribute --type nodes --node pcmk-1 --name kernel --update $(uname -r)
-------
[source,XML]
-------
<node uname="pcmk-1" type="normal" id="101">
   <instance_attributes id="nodes-101">
     <nvpair id="nodes-101-kernel" name="kernel" value="3.10.0-123.13.2.el7.x86_64"/>
   </instance_attributes>
</node>
-------
======
Rather than having to read the XML, a simpler way to determine the current
value of an attribute is to use `crm_attribute` again:

----
# crm_attribute --type nodes --node pcmk-1 --name kernel --query
scope=nodes  name=kernel value=3.10.0-123.13.2.el7.x86_64
----

By specifying `--type nodes` the admin tells the cluster that this
attribute is persistent.  There are also transient attributes which
are kept in the status section which are "forgotten" whenever the node
rejoins the cluster.  The cluster uses this area to store a record of
how many times a resource has failed on that node, but administrators
can also read and write to this section by specifying `--type status`.
